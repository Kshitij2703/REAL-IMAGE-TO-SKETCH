{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6524509,"sourceType":"datasetVersion","datasetId":3772012}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"  \n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:24:10.870526Z","iopub.execute_input":"2024-11-01T18:24:10.870923Z","iopub.status.idle":"2024-11-01T18:24:10.881620Z","shell.execute_reply.started":"2024-11-01T18:24:10.870881Z","shell.execute_reply":"2024-11-01T18:24:10.880597Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\n\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"Using GPUs:\", gpus)\n    except RuntimeError as e:\n        print(\"Error initializing GPUs:\", e)\nelse:\n    print(\"No GPUs available.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:24:18.857142Z","iopub.execute_input":"2024-11-01T18:24:18.858045Z","iopub.status.idle":"2024-11-01T18:24:22.406514Z","shell.execute_reply.started":"2024-11-01T18:24:18.857988Z","shell.execute_reply":"2024-11-01T18:24:22.405545Z"}},"outputs":[{"name":"stdout","text":"Using GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"for gpu in tf.config.list_physical_devices('GPU'):\n    tf.config.experimental.set_memory_growth(gpu, True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:25:44.414493Z","iopub.execute_input":"2024-11-01T18:25:44.415666Z","iopub.status.idle":"2024-11-01T18:25:44.420405Z","shell.execute_reply.started":"2024-11-01T18:25:44.415620Z","shell.execute_reply":"2024-11-01T18:25:44.419412Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport keras\nfrom keras import optimizers\nfrom tqdm import tqdm\nimport gc\nimport psutil\n\nclass PhotoSketchDataset:\n    def __init__(self, color_dir, sketch_dir):\n        self.color_dir = color_dir\n        self.sketch_dir = sketch_dir\n        self.color_files = []\n        self.sketch_files = []\n        \n    def load_image_paths(self, preprocess_fraction=0.1):\n        self.color_files = sorted(os.listdir(self.color_dir))\n        self.sketch_files = sorted(os.listdir(self.sketch_dir))\n        \n        n_samples = int(len(self.color_files) * preprocess_fraction)\n        self.color_files = self.color_files[:n_samples]\n        self.sketch_files = self.sketch_files[:n_samples]\n        \n        train_color, temp_color, train_sketch, temp_sketch = train_test_split(\n            self.color_files, self.sketch_files, train_size=0.7, random_state=42\n        )\n        \n        val_ratio = 0.5\n        val_color, test_color, val_sketch, test_sketch = train_test_split(\n            temp_color, temp_sketch, train_size=val_ratio, random_state=42\n        )\n        \n        return (train_color, train_sketch), (val_color, val_sketch), (test_color, test_sketch)\n    \n    @staticmethod\n    def load_and_preprocess_image(image_path, target_size=(256, 256)):\n        img = cv2.imread(image_path)\n        if img is not None:\n            img = cv2.resize(img, target_size)\n            img = img.astype(np.float32) / 127.5 - 1\n            return img\n        return None\n\n    def data_generator(self, color_files, sketch_files, batch_size=4):\n        num_samples = len(color_files)\n        while True:\n            indices = np.random.permutation(num_samples)\n            for start_idx in range(0, num_samples, batch_size):\n                batch_indices = indices[start_idx:start_idx + batch_size]\n                \n                batch_color = []\n                batch_sketch = []\n                \n                for idx in batch_indices:\n                    color_path = os.path.join(self.color_dir, color_files[idx])\n                    sketch_path = os.path.join(self.sketch_dir, sketch_files[idx])\n                    \n                    color_img = self.load_and_preprocess_image(color_path)\n                    sketch_img = self.load_and_preprocess_image(sketch_path)\n                    \n                    if color_img is not None and sketch_img is not None:\n                        batch_color.append(color_img)\n                        batch_sketch.append(sketch_img)\n                \n                if batch_color and batch_sketch:\n                    yield np.array(batch_color), np.array(batch_sketch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:38:46.031421Z","iopub.execute_input":"2024-11-01T18:38:46.031824Z","iopub.status.idle":"2024-11-01T18:38:46.048021Z","shell.execute_reply.started":"2024-11-01T18:38:46.031786Z","shell.execute_reply":"2024-11-01T18:38:46.047032Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class MemoryEfficientCycleGAN:\n    def __init__(self):\n        self.lambda_cycle = 10.0\n        self.checkpoint_dir = './training_checkpoints'\n        os.makedirs(self.checkpoint_dir, exist_ok=True)\n        \n        self.generator_g = self._build_generator()\n        self.generator_f = self._build_generator()\n        self.discriminator_x = self._build_discriminator()\n        self.discriminator_y = self._build_discriminator()\n        \n        self.generator_g_optimizer = optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n        self.generator_f_optimizer = optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n        self.discriminator_x_optimizer = optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n        self.discriminator_y_optimizer = optimizers.Adam(learning_rate=2e-4, beta_1=0.5)\n    \n    def _build_generator(self):\n        inputs = keras.layers.Input(shape=[256, 256, 3])\n        \n        x = keras.layers.Conv2D(64, 4, strides=2, padding='same')(inputs)\n        x = keras.layers.LeakyReLU()(x)\n        \n        x = keras.layers.Conv2D(128, 4, strides=2, padding='same')(x)\n        x = keras.layers.BatchNormalization()(x)\n        x = keras.layers.LeakyReLU()(x)\n        \n        x = keras.layers.Conv2DTranspose(64, 4, strides=2, padding='same')(x)\n        x = keras.layers.BatchNormalization()(x)\n        x = keras.layers.ReLU()(x)\n        \n        outputs = keras.layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')(x)\n        \n        return keras.Model(inputs=inputs, outputs=outputs)\n    \n    def _build_discriminator(self):\n        inputs = keras.layers.Input(shape=[256, 256, 3])\n        \n        x = keras.layers.Conv2D(64, 4, strides=2, padding='same')(inputs)\n        x = keras.layers.LeakyReLU()(x)\n        \n        x = keras.layers.Conv2D(128, 4, strides=2, padding='same')(x)\n        x = keras.layers.BatchNormalization()(x)\n        x = keras.layers.LeakyReLU()(x)\n        \n        outputs = keras.layers.Conv2D(1, 4, strides=1, padding='same')(x)\n        \n        return keras.Model(inputs=inputs, outputs=outputs)\n\n    def _generator_loss(self, generated_output, real_target, source, cycled_source):\n        gen_loss = tf.reduce_mean(keras.losses.binary_crossentropy(\n            tf.ones_like(generated_output), generated_output))\n        \n        cycle_loss = tf.reduce_mean(tf.abs(source - cycled_source))\n        total_loss = gen_loss + self.lambda_cycle * cycle_loss\n        \n        return total_loss, gen_loss, cycle_loss\n\n    def _discriminator_loss(self, real_output, generated_output):\n        real_loss = keras.losses.binary_crossentropy(tf.ones_like(real_output), real_output)\n        generated_loss = keras.losses.binary_crossentropy(tf.zeros_like(generated_output), generated_output)\n        total_loss = tf.reduce_mean(real_loss + generated_loss)\n        return total_loss\n\n    @tf.function\n    def train_step(self, real_x, real_y):\n        with tf.GradientTape(persistent=True) as tape:\n            fake_y = self.generator_g(real_x, training=True)\n            fake_x = self.generator_f(real_y, training=True)\n            \n            cycled_x = self.generator_f(fake_y, training=True)\n            cycled_y = self.generator_g(fake_x, training=True)\n            \n            disc_real_x = self.discriminator_x(real_x, training=True)\n            disc_fake_x = self.discriminator_x(fake_x, training=True)\n            disc_real_y = self.discriminator_y(real_y, training=True)\n            disc_fake_y = self.discriminator_y(fake_y, training=True)\n            \n            gen_g_total_loss, gen_g_loss, cycle_g_loss = self._generator_loss(\n                disc_fake_y, real_y, real_x, cycled_x)\n            gen_f_total_loss, gen_f_loss, cycle_f_loss = self._generator_loss(\n                disc_fake_x, real_x, real_y, cycled_y)\n            \n            disc_x_loss = self._discriminator_loss(disc_real_x, disc_fake_x)\n            disc_y_loss = self._discriminator_loss(disc_real_y, disc_fake_y)\n        \n        generator_g_gradients = tape.gradient(gen_g_total_loss, self.generator_g.trainable_variables)\n        generator_f_gradients = tape.gradient(gen_f_total_loss, self.generator_f.trainable_variables)\n        discriminator_x_gradients = tape.gradient(disc_x_loss, self.discriminator_x.trainable_variables)\n        discriminator_y_gradients = tape.gradient(disc_y_loss, self.discriminator_y.trainable_variables)\n        \n        self.generator_g_optimizer.apply_gradients(\n            zip(generator_g_gradients, self.generator_g.trainable_variables))\n        self.generator_f_optimizer.apply_gradients(\n            zip(generator_f_gradients, self.generator_f.trainable_variables))\n        self.discriminator_x_optimizer.apply_gradients(\n            zip(discriminator_x_gradients, self.discriminator_x.trainable_variables))\n        self.discriminator_y_optimizer.apply_gradients(\n            zip(discriminator_y_gradients, self.discriminator_y.trainable_variables))\n        \n        return {\n            'gen_g_loss': gen_g_loss,\n            'gen_f_loss': gen_f_loss,\n            'disc_x_loss': disc_x_loss,\n            'disc_y_loss': disc_y_loss,\n            'cycle_loss': (cycle_g_loss + cycle_f_loss) / 2\n        }\n\n    def train(self, dataset, train_files, epochs=200, batch_size=4, save_interval=10):\n        steps_per_epoch = len(train_files[0]) // batch_size\n        \n        for epoch in range(epochs):\n            print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n            generator = dataset.data_generator(train_files[0], train_files[1], batch_size)\n            \n            progress_bar = tqdm(range(steps_per_epoch))\n            for _ in progress_bar:\n                batch_x, batch_y = next(generator)\n                losses = self.train_step(batch_x, batch_y)\n                \n                progress_bar.set_description(\n                    f\"G_loss: {(losses['gen_g_loss'] + losses['gen_f_loss'])/2:.4f}, \"\n                    f\"D_loss: {(losses['disc_x_loss'] + losses['disc_y_loss'])/2:.4f}, \"\n                    f\"Cycle_loss: {losses['cycle_loss']:.4f}\")\n                \n                current_memory = psutil.Process().memory_info().rss / 1024 / 1024 / 1024\n                if current_memory > 25:  \n                    gc.collect()\n                    tf.keras.backend.clear_session()\n            \n            if (epoch + 1) % save_interval == 0:\n                self.save_models(epoch + 1)\n            \n            gc.collect()\n    \n    def save_models(self, epoch):\n        self.generator_g.save(f'generator_g_epoch_{epoch}.keras')\n        self.generator_f.save(f'generator_f_epoch_{epoch}.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:38:48.941696Z","iopub.execute_input":"2024-11-01T18:38:48.942109Z","iopub.status.idle":"2024-11-01T18:38:48.974444Z","shell.execute_reply.started":"2024-11-01T18:38:48.942070Z","shell.execute_reply":"2024-11-01T18:38:48.973473Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    dataset = PhotoSketchDataset(\n        color_dir='/kaggle/input/anime-colorization/color',\n        sketch_dir='/kaggle/input/anime-colorization/sketch'\n    )\n    \n    train_files, val_files, test_files = dataset.load_image_paths(preprocess_fraction=0.1)\n    \n    cycle_gan = MemoryEfficientCycleGAN()\n    cycle_gan.train(dataset, train_files, epochs=5, batch_size=16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:38:57.880474Z","iopub.execute_input":"2024-11-01T18:38:57.881262Z","iopub.status.idle":"2024-11-01T18:51:20.212517Z","shell.execute_reply.started":"2024-11-01T18:38:57.881221Z","shell.execute_reply":"2024-11-01T18:51:20.211503Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"G_loss: 6.2228, D_loss: 9.0390, Cycle_loss: 0.6662: 100%|██████████| 294/294 [02:57<00:00,  1.66it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"G_loss: 4.0426, D_loss: 9.7134, Cycle_loss: 0.5269: 100%|██████████| 294/294 [02:24<00:00,  2.03it/s] \n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"G_loss: 2.3677, D_loss: 3.9286, Cycle_loss: 0.4792: 100%|██████████| 294/294 [02:15<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"G_loss: 1.6448, D_loss: 1.2303, Cycle_loss: 0.4014: 100%|██████████| 294/294 [02:16<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"G_loss: 1.1475, D_loss: 1.6121, Cycle_loss: 0.3711: 100%|██████████| 294/294 [02:25<00:00,  2.02it/s]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"cycle_gan.generator_g.save('generator_g_final.keras')\ncycle_gan.generator_f.save('generator_f_final.keras')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:53:58.965062Z","iopub.execute_input":"2024-11-01T18:53:58.966049Z","iopub.status.idle":"2024-11-01T18:53:59.031187Z","shell.execute_reply.started":"2024-11-01T18:53:58.966004Z","shell.execute_reply":"2024-11-01T18:53:59.030259Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def generate_sketch(color_image_path, generator):\n    color_img = PhotoSketchDataset.load_and_preprocess_image(color_image_path)\n    \n    if color_img is not None:\n        color_img = np.expand_dims(color_img, axis=0)\n        \n        sketch_img = generator.predict(color_img)\n        \n        sketch_img = (sketch_img[0] + 1) / 2.0  \n        sketch_img = (sketch_img * 255).astype(np.uint8)  \n        \n        return sketch_img\n    return None\n\nif __name__ == \"__main__\":\n    generator_g = keras.models.load_model('generator_g_final.keras')\n    \n    sketch_image = generate_sketch('/kaggle/input/anime-colorization/color/1000241.png', generator_g)\n    \n    cv2.imwrite('generated_sketch.jpg', sketch_image)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:54:45.161693Z","iopub.execute_input":"2024-11-01T18:54:45.162413Z","iopub.status.idle":"2024-11-01T18:54:46.503863Z","shell.execute_reply.started":"2024-11-01T18:54:45.162367Z","shell.execute_reply":"2024-11-01T18:54:46.502792Z"}},"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730487285.458234     252 service.cc:145] XLA service 0x7f9b08005c90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730487285.458311     252 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730487285.458320     252 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1730487286.481143     252 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"}],"execution_count":16}]}